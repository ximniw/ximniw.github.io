[{"content":"keywords P-GNN-CON, I-GNN-CON(提出的模型) Cross-Modal Retrieval(跨模态检索) Multi-Label Contrastive Learning(多标签对比学习) Dual Adversarial Graph Neural Networks(Dual GAN) GAN(生成对抗网络) Generative Adversarial Networks multi-hop Gragh Neural Networks GNN(图神经网络)Graph Neural Networks Background 传统完成跨模态检索任务，通常需要将不同模态的数据映射到同一表征空间，以解决不同模态数据间的差异\n现有方法的缺陷：1）引入损失可能无法消除模态间的差异； 2）实际应用中的数据大多来自单一模态，完整模态数据很稀少，而现有方法大多假定样本的所有模态数据是完整的； 3）忽视了多模态数据的标签间的相关性，不利于建立多模态数据间的语义联系 4）样本被简单分类为0，1，但实际上样本标签的相似度很难完全相同或不同，不适应多标签情况\n要解决的问题：1）消除模态间的差异，从而去除特定模态的信息，完全保留语义信息 2）捕捉了标签的相关性，驱动模型学习判别特征 3） 在标签相似度0和1之间建立离散的模型\nsolution 对于问题1：设计了Dual GAN，生成共同表征同时重构一些原始表征，其中生成模型学习多模态联合数据的分布并生成一些伪表征，判别模型学习判断原始表征和伪表征。通过优化对抗损失以去除特定模态特征并保留语义信息； 对于问题2：提出multi-hop Gragh Neural Networks(P-GNN,I-GNN)来生成inter-dependent的标签分类器,用学习到的分类器对Dual GAN生成的共同表征进行分类，来完成端到端训练并利用分类损失帮助模型学习underlying semantic structure 对于问题3：为Multi-label Cross-modal Contrastive Learning提出了新的soft multi-label contrastive loss和soft positive sampling 实现非二元的标签相似度 related work 跨模态检索 学习共同表征的两种方式：\n传统多模态表征学习(Canonical Correlation Analysis (CCA),Joint Representation Learning (JRL)) 深度多模态表征学习(Deep Canonical Correlation Analysis (DCCA),Probabilistic Cross-Modal Embedding (PCME),Multi-modal Robust Learning (MRL)，T2VLAD(完成文本视频检索任务)，Adversarial Cross-Modal Retrieval model (ACMR)，Deep Supervised Cross-modal Retrieval (DSCMR)\u0026hellip;) GNN Graph Laplacian:多应用于GNN中 GCN，AGCN，GaAN (图学习)\nmethod P-GNN-CON\nI-GNN-CON\n模型主要由Dual GAN和multi-hop Gragh Neural Networks组成\nImage and Text Encoding Network 将图像和文本特征分别投射到一个共同的表示空间\n对于图像，使用19层的VGGNet(在ImageNet上进行过预训练)得到特征,然后通过多个全连接层投射到共同表示空间 对于文本，使用有两层全连接层的MLP(预训练过)得到特征,然后通过多个全连接层投射到共同表示空间 Dual Generative Adversarial Networks ImgGAN和TxtGAN，两个生成器和判别器，生成器将分别文本和图像的共同表征重构为另一表征作为伪表征，判别器通过判别原始表征和伪表征来学习判别模态，模态间的差异可以被消除。\n因为可以生成另一模态的伪特征，可以用ImgGAN和TxtGAN来解决数据模态不完整的问题。\nMulti-hop Graph Neural Networks 用标签相关图来生成inter-dependent的分类器，学习到的分类器应用于共同表示空间中，使模型能够学习语义结构和判别表征\nP-GNN中是通过label embeddings和概率相关矩阵构建标签相关图，I-GNN中是通过迭代学习方式构建标签相关图\n概率相关矩阵：基于标签共同出现的概率，为防止不常见的共现标签的噪声干扰和标签共现的频率不恒定，使用了一个阈值对矩阵0-1化，并使用重新加权的技巧防止过度平滑 迭代性相关图：基于深度学习迭代，可以得到更好的图结构 Multi-label Cross-modal Contrastive Learning 提出了soft multi-label contrastive loss和Soft Positive Sampling\n将有相似标签的表征拉到一起并将不同类别的表征推开，而不受模态影响\nMulti-label Cross-modal Contrastive Learning的噪声：在多标签情况下，将样本推向正样本时，正样本可能包含其他类别，回导致样本同时更接近其他类别的样本\n将soft multi-label contrastive loss与P-GNN和I-GNN结合，就得到了P-GNN-CON和I-GNN-CON\n","permalink":"/posts/%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB1/","summary":"keywords P-GNN-CON, I-GNN-CON(提出的模型) Cross-Modal Retrieval(跨模态检索) Multi-Label Contrastive Learning(多标签对比学习) Dual Adversarial Graph Neural Networks(Dual GAN) GAN(生成对抗网络) Generative Adversarial Networks multi-hop Gragh Neural Networks GNN(图神经网络)Graph Neural Networks Background 传统完成跨模态检索任务，通常需要将不同模态的数据映射到同一表征空间，以解决不同模态数据间的差异\n现有方法的缺陷：1）引入损失可能无法消除模态间的差异； 2）实际应用中的数据大多来自单一模态，完整模态数据很稀少，而现有方法大多假定样本的所有模态数据是完整的； 3）忽视了多模态数据的标签间的相关性，不利于建立多模态数据间的语义联系 4）样本被简单分类为0，1，但实际上样本标签的相似度很难完全相同或不同，不适应多标签情况\n要解决的问题：1）消除模态间的差异，从而去除特定模态的信息，完全保留语义信息 2）捕捉了标签的相关性，驱动模型学习判别特征 3） 在标签相似度0和1之间建立离散的模型\nsolution 对于问题1：设计了Dual GAN，生成共同表征同时重构一些原始表征，其中生成模型学习多模态联合数据的分布并生成一些伪表征，判别模型学习判断原始表征和伪表征。通过优化对抗损失以去除特定模态特征并保留语义信息； 对于问题2：提出multi-hop Gragh Neural Networks(P-GNN,I-GNN)来生成inter-dependent的标签分类器,用学习到的分类器对Dual GAN生成的共同表征进行分类，来完成端到端训练并利用分类损失帮助模型学习underlying semantic structure 对于问题3：为Multi-label Cross-modal Contrastive Learning提出了新的soft multi-label contrastive loss和soft positive sampling 实现非二元的标签相似度 related work 跨模态检索 学习共同表征的两种方式：\n传统多模态表征学习(Canonical Correlation Analysis (CCA),Joint Representation Learning (JRL)) 深度多模态表征学习(Deep Canonical Correlation Analysis (DCCA),Probabilistic Cross-Modal Embedding (PCME),Multi-modal Robust Learning (MRL)，T2VLAD(完成文本视频检索任务)，Adversarial Cross-Modal Retrieval model (ACMR)，Deep Supervised Cross-modal Retrieval (DSCMR)\u0026hellip;) GNN Graph Laplacian:多应用于GNN中 GCN，AGCN，GaAN (图学习)","title":"论文研读-Integrating Multi-Label Contrastive Learning with Dual Adversarial Graph Neural Networks for Cross-Modal Retrieval"},{"content":"","permalink":"/posts/first/","summary":"","title":"第一篇blog"}]